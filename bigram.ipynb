{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Importing all the important libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "# import mmap\n",
    "# import random\n",
    "# import pickle \n",
    "# import argparse\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "# Setting all the hyperparamters\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 20000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 1000\n",
    "n_embd = 384\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '1', '2', '3', '4', '5', '6', '8', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'ê']\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "# This is to read the text from the book\n",
    "with open('pride_and_prejudice.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# print(len(text))  # Length of the text\n",
    "# print(text[:100]) # first 100 characters\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" hello \" : [56, 53, 60, 60, 63]\n"
     ]
    }
   ],
   "source": [
    "# This is the code for the character-level tokenizer\n",
    "string_to_int = { ch:i for i, ch in enumerate(chars)}\n",
    "int_to_string = { i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "encoded_s = encode(\"hello\")\n",
    "decoded_s = decode(encoded_s)\n",
    "print(\"\\\" \" + str(decoded_s) + \" \\\" : \" + str(encoded_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIDE & PREJUDICE.\n",
      "\n",
      "CHAPTER I.\n",
      "\n",
      "It is a truth universally acknowledged, that a single man in possess\n",
      "\n",
      "tensor([37, 38, 30, 25, 26,  1,  4,  1, 37, 38, 26, 31, 41, 25, 30, 24, 26, 11,\n",
      "         0,  0, 24, 29, 22, 37, 40, 26, 38,  1, 30, 11,  0,  0, 30, 68,  1, 57,\n",
      "        67,  1, 49,  1, 68, 66, 69, 68, 56,  1, 69, 62, 57, 70, 53, 66, 67, 49,\n",
      "        60, 60, 73,  1, 49, 51, 59, 62, 63, 71, 60, 53, 52, 55, 53, 52,  9,  1,\n",
      "        68, 56, 49, 68,  1, 49,  1, 67, 57, 62, 55, 60, 53,  1, 61, 49, 62,  1,\n",
      "        57, 62,  1, 64, 63, 67, 67, 53, 67, 67])\n"
     ]
    }
   ],
   "source": [
    "# Better to use a PyTorch Tensors\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(text[:100])\n",
    "print()\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into train and validation\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        \n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim = -1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1) \n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head = n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim = -1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples = 1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim = 1) # (B, T+1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LargeLanguageModel(vocab_size)\n",
    "# print('loading model parameters...')\n",
    "# with open('model-01.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)\n",
    "# print('loaded successfully!')\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/20000 [00:37<206:51:08, 37.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Train loss: 4.480, Val loss: 4.480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1001/20000 [02:28<28:42:14,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000, Train loss: 2.322, Val loss: 2.309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2001/20000 [04:15<23:12:29,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000, Train loss: 2.197, Val loss: 2.176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3001/20000 [06:02<21:52:43,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3000, Train loss: 2.103, Val loss: 2.096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4000/20000 [08:07<25:10, 10.59it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000, Train loss: 2.073, Val loss: 2.075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5001/20000 [10:50<21:45:21,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000, Train loss: 2.059, Val loss: 2.032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6001/20000 [12:48<18:28:02,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000, Train loss: 2.023, Val loss: 2.036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7001/20000 [14:37<36:16:58, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7000, Train loss: 1.993, Val loss: 1.979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8001/20000 [16:36<17:52:24,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8000, Train loss: 1.946, Val loss: 1.958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9001/20000 [18:33<18:05:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9000, Train loss: 1.973, Val loss: 1.944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10001/20000 [20:41<19:37:30,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000, Train loss: 1.927, Val loss: 1.933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11001/20000 [22:38<12:42:09,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11000, Train loss: 1.912, Val loss: 1.933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12001/20000 [24:19<9:35:29,  4.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12000, Train loss: 1.932, Val loss: 1.920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13001/20000 [26:12<9:17:36,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13000, Train loss: 1.902, Val loss: 1.907\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14001/20000 [28:00<7:54:47,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14000, Train loss: 1.888, Val loss: 1.895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15001/20000 [29:50<6:34:02,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000, Train loss: 1.886, Val loss: 1.883\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16001/20000 [31:38<5:13:02,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16000, Train loss: 1.871, Val loss: 1.876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17001/20000 [33:25<3:47:50,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17000, Train loss: 1.868, Val loss: 1.893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18001/20000 [35:05<2:24:29,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18000, Train loss: 1.869, Val loss: 1.864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19001/20000 [36:56<1:35:20,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19000, Train loss: 1.852, Val loss: 1.854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [38:11<00:00,  8.73it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 1.585258960723877\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 47min 34s, sys: 1h 45min 43s, total: 4h 33min 17s\n",
      "Wall time: 38min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in tqdm(range(max_iters)):\n",
    "    # print(iter)\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_losses.append(losses['train'])\n",
    "        val_losses.append(losses['val'])\n",
    "\n",
    "        print(f\"Step: {iter}, Train loss: {losses['train']:.3f}, Val loss: {losses['val']:.3f}\")\n",
    "        print()\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final Loss: \" + str(loss.item()) + \"\\n\")\n",
    "\n",
    "# Plotting the training and validation losses\n",
    "plt.plot(range(0, max_iters, eval_iters), train_losses, label='Train Loss')\n",
    "plt.plot(range(0, max_iters, eval_iters), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do \n"
     ]
    }
   ],
   "source": [
    "prompt = 'd'\n",
    "context = torch.tensor(encode(prompt), dtype = torch.long, device = device)\n",
    "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens = 100)[0].tolist())\n",
    "print(generated_chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
